{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DESAFÍO SEGUROS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargar la data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_desafio_seguros')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generar variables dummies con one-hot-encoding para las variables descriptivas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns = ['0','2','3','3','5','6','8','9','11','13','14','16'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Booleanizar variables descriptivas o numéricas con sólo dos opciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['18'] = df['18'].replace('A191', 0)\n",
    "df['18']=df['18'].replace('A192',1)\n",
    "df['19']=df['19'].replace('A201', 0)\n",
    "df['19']=df['19'].replace('A202', 1)\n",
    "df['20']=df['20'].replace(2, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizar los datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = list(df.columns)\n",
    "x = df.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "df = pd.DataFrame(x_scaled, columns=feature_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separar la data correspondiente a variables (X) y a clasificación (y). \n",
    "\n",
    "Dividir en entrenamiento y testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['20']\n",
    "X = df.copy()\n",
    "X = X.drop('20',1)\n",
    "X = X.drop('row_id',1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red Neuronal\n",
    "\n",
    "Se itera sobre el tamaño para minimizar falsos positivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max = 400\n",
    "min_fpr = 1\n",
    "for i in range (10,max,20):\n",
    "    for j in range(10,max,20):\n",
    "\n",
    "        clf = MLPClassifier(activation='relu', hidden_layer_sizes=(i,j), solver='lbfgs')\n",
    "\n",
    "        neural_model = clf.fit(X_train, y_train)\n",
    "        y_pred = neural_model.predict(X_test)\n",
    "        #y_prob= neural_model.predict_proba(X_test)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test,y_pred).ravel()\n",
    "        fpr = fp/(tn+fp)\n",
    "        tpr = tp/(tp+fn)\n",
    "        if fpr < min_fpr and tpr>fpr:\n",
    "            min_fpr = fpr\n",
    "            min_model = clf\n",
    "        if((i%110==0) or (j%110==0)):\n",
    "            print(i,j)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtener matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 49,  36],\n",
       "       [ 39, 146]], dtype=int64)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = min_model.predict(X_test)\n",
    "y_prob= min_model.predict_proba(X_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test,y_pred).ravel()\n",
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardar red neuronal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "filename = 'arn.sav'\n",
    "pickle.dump(min_model, open(filename, 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtener métricas importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4235294117647059 0.7891891891891892 0.8021978021978022\n"
     ]
    }
   ],
   "source": [
    "fpr = fp/(tn+fp)\n",
    "tpr = tp/(tp+fn)\n",
    "ppv = tp/(tp+fp)\n",
    "print(fpr,tpr,ppv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.22629122e-07, 9.99999877e-01])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
